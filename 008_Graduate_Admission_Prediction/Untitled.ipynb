{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d74bd2b-193c-4657-9e4e-2d6f038d9663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a39d063-bd49-4425-89fa-57051d6f294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ecb817e-743e-4bce-a8e6-5747a3447965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61f11363-860b-402a-8796-d45423915115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e2add1-9377-413a-9fcf-e9a3622626f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3164a659-4206-4c0b-8e86-4cdb6b8fb07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69a0f1e2-2ce8-4269-822f-15d83534b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74a3c91b-c932-4a64-be90-d092d0b024c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c58f2e5c-4933-42d6-80a6-9e23a79e10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da1a9419-8798-478d-95d4-c9d64493e9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beecc915-07bc-4e3a-bfad-a680b23f2812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "552df900-648e-4b1c-980a-18085f4cbd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5877d45b-48a2-417f-8a02-15d77af830a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>300</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "238        310          104                  3  2.0   3.5  8.37         0\n",
       "438        318          110                  1  2.5   3.5  8.54         1\n",
       "475        300          101                  3  3.5   2.5  7.88         0\n",
       "58         300           99                  1  3.0   2.0  6.80         1\n",
       "380        322          104                  3  3.5   4.0  8.84         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75012709-4efa-490a-9490-2f4e720ca738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e91a12d-e5b0-4afe-b0f1-ba2f3eeff08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92c82ebc-109c-425c-96a2-35d895eec579",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d23fac6-cf47-42e6-ae12-7f34c34aa331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46849e90-11b2-4347-b378-7f3bb4d613d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46      ,  0.5       ,  0.25      ,  0.375     ,  0.14285714,\n",
       "         0.5224359 ,  0.        ],\n",
       "       [ 0.44      ,  0.53571429,  0.5       ,  0.5       ,  0.42857143,\n",
       "         0.53205128,  1.        ],\n",
       "       [ 0.98      ,  0.96428571,  1.        ,  0.875     ,  0.71428571,\n",
       "         0.92948718,  0.        ],\n",
       "       [ 0.52      ,  0.53571429,  0.25      ,  0.625     ,  0.57142857,\n",
       "         0.58974359,  1.        ],\n",
       "       [ 0.7       ,  0.64285714,  0.75      ,  0.875     ,  0.71428571,\n",
       "         0.69230769,  1.        ],\n",
       "       [ 0.42      ,  0.32142857,  0.25      ,  0.375     ,  0.57142857,\n",
       "         0.49358974,  1.        ],\n",
       "       [ 0.6       ,  0.42857143,  0.5       ,  0.5       ,  0.57142857,\n",
       "         0.62179487,  1.        ],\n",
       "       [ 0.74      ,  0.39285714,  0.5       ,  0.75      ,  0.71428571,\n",
       "         0.48076923,  1.        ],\n",
       "       [ 0.62      ,  0.67857143,  0.5       ,  0.625     ,  0.71428571,\n",
       "         0.65064103,  1.        ],\n",
       "       [ 0.56      ,  0.5       ,  0.25      ,  0.75      ,  0.71428571,\n",
       "         0.35897436,  1.        ],\n",
       "       [ 0.48      ,  0.53571429,  0.25      ,  0.375     ,  0.71428571,\n",
       "         0.47115385,  0.        ],\n",
       "       [ 0.06      ,  0.17857143,  0.25      ,  0.25      ,  0.71428571,\n",
       "         0.32051282,  1.        ],\n",
       "       [ 0.74      ,  0.42857143,  1.        ,  0.5       ,  0.57142857,\n",
       "         0.65384615,  1.        ],\n",
       "       [ 0.74      ,  0.78571429,  0.5       ,  0.5       ,  0.42857143,\n",
       "         0.71153846,  0.        ],\n",
       "       [ 0.62      ,  0.60714286,  0.5       ,  0.625     ,  0.57142857,\n",
       "         0.64102564,  1.        ],\n",
       "       [ 0.68      ,  0.71428571,  1.        ,  1.        ,  1.        ,\n",
       "         0.73076923,  1.        ],\n",
       "       [ 0.32      ,  0.39285714,  0.5       ,  0.625     ,  0.42857143,\n",
       "         0.45192308,  0.        ],\n",
       "       [ 0.46      ,  0.60714286,  0.5       ,  0.75      ,  0.57142857,\n",
       "         0.70512821,  0.        ],\n",
       "       [ 0.82      ,  0.82142857,  1.        ,  0.75      ,  0.57142857,\n",
       "         0.84615385,  1.        ],\n",
       "       [ 0.5       ,  0.46428571,  0.5       ,  0.25      ,  0.28571429,\n",
       "         0.53846154,  0.        ],\n",
       "       [ 0.44      ,  0.21428571,  0.        ,  0.625     ,  0.42857143,\n",
       "         0.44230769,  1.        ],\n",
       "       [ 0.42      ,  0.53571429,  0.75      ,  0.875     ,  0.85714286,\n",
       "         0.70512821,  1.        ],\n",
       "       [ 0.76      ,  0.57142857,  0.75      ,  0.875     ,  0.71428571,\n",
       "         0.76282051,  1.        ],\n",
       "       [ 0.16      ,  0.32142857,  0.75      ,  0.375     ,  0.85714286,\n",
       "         0.28525641,  1.        ],\n",
       "       [ 0.7       ,  0.71428571,  0.75      ,  0.625     ,  0.57142857,\n",
       "         0.67948718,  0.        ],\n",
       "       [ 0.5       ,  0.46428571,  0.25      ,  0.25      ,  0.28571429,\n",
       "         0.2724359 ,  0.        ],\n",
       "       [ 0.82      ,  0.71428571,  1.        ,  0.75      ,  1.        ,\n",
       "         0.96153846,  1.        ],\n",
       "       [ 0.36      ,  0.5       ,  0.5       ,  0.5       ,  0.42857143,\n",
       "         0.46153846,  0.        ],\n",
       "       [ 0.66      ,  0.75      ,  0.75      ,  0.75      ,  0.85714286,\n",
       "         0.77884615,  1.        ],\n",
       "       [ 0.5       ,  0.64285714,  0.25      ,  0.625     ,  0.42857143,\n",
       "         0.53205128,  1.        ],\n",
       "       [ 0.34      ,  0.35714286,  0.5       ,  0.5       ,  0.42857143,\n",
       "         0.47115385,  0.        ],\n",
       "       [ 0.66      ,  0.64285714,  0.5       ,  0.75      ,  0.57142857,\n",
       "         0.73717949,  1.        ],\n",
       "       [ 0.28      ,  0.28571429,  0.25      ,  0.375     ,  0.57142857,\n",
       "         0.40705128,  0.        ],\n",
       "       [ 0.82      ,  0.85714286,  0.75      ,  0.875     ,  0.85714286,\n",
       "         0.84615385,  1.        ],\n",
       "       [ 0.52      ,  0.21428571,  0.        ,  0.125     ,  0.14285714,\n",
       "         0.20192308,  0.        ],\n",
       "       [ 0.72      ,  0.71428571,  0.5       ,  0.625     ,  0.42857143,\n",
       "         0.73717949,  1.        ],\n",
       "       [ 0.6       ,  0.32142857,  0.25      ,  0.375     ,  0.42857143,\n",
       "         0.58333333,  0.        ],\n",
       "       [ 0.48      ,  0.39285714,  0.25      ,  0.25      ,  0.42857143,\n",
       "         0.45192308,  0.        ],\n",
       "       [ 0.5       ,  0.46428571,  0.25      ,  0.5       ,  0.42857143,\n",
       "         0.49358974,  0.        ],\n",
       "       [ 0.88      ,  0.85714286,  0.75      ,  0.75      ,  0.57142857,\n",
       "         0.87820513,  1.        ],\n",
       "       [ 0.18      ,  0.28571429,  0.5       ,  0.25      ,  0.14285714,\n",
       "         0.39102564,  0.        ],\n",
       "       [ 0.42      ,  0.42857143,  0.5       ,  0.75      ,  0.57142857,\n",
       "         0.42628205,  1.        ],\n",
       "       [ 0.56      ,  0.32142857,  1.        ,  0.625     ,  1.        ,\n",
       "         0.63461538,  1.        ],\n",
       "       [ 0.86      ,  0.96428571,  1.        ,  1.        ,  0.85714286,\n",
       "         0.95512821,  1.        ],\n",
       "       [ 0.74      ,  0.75      ,  0.5       ,  0.625     ,  0.42857143,\n",
       "         0.59615385,  1.        ],\n",
       "       [ 0.14      ,  0.14285714,  0.25      ,  0.375     ,  0.        ,\n",
       "         0.34935897,  0.        ],\n",
       "       [ 0.54      ,  0.28571429,  0.25      ,  0.5       ,  0.28571429,\n",
       "         0.56730769,  0.        ],\n",
       "       [ 0.5       ,  0.42857143,  0.5       ,  0.75      ,  0.28571429,\n",
       "         0.41666667,  0.        ],\n",
       "       [ 0.64      ,  0.39285714,  0.75      ,  0.5       ,  0.28571429,\n",
       "         0.39102564,  1.        ],\n",
       "       [ 0.48      ,  0.5       ,  0.25      ,  0.75      ,  0.57142857,\n",
       "         0.46474359,  0.        ],\n",
       "       [ 0.78      ,  0.67857143,  0.75      ,  0.875     ,  0.71428571,\n",
       "         0.70833333,  1.        ],\n",
       "       [ 0.82      ,  0.89285714,  0.75      ,  0.875     ,  1.        ,\n",
       "         0.83974359,  1.        ],\n",
       "       [ 0.8       ,  0.82142857,  1.        ,  0.875     ,  0.42857143,\n",
       "         0.81410256,  1.        ],\n",
       "       [ 0.36      ,  0.35714286,  0.25      ,  0.25      ,  0.57142857,\n",
       "         0.37820513,  1.        ],\n",
       "       [ 0.5       ,  0.32142857,  0.5       ,  0.625     ,  0.85714286,\n",
       "         0.74679487,  0.        ],\n",
       "       [ 0.28      ,  0.46428571,  0.25      ,  0.5       ,  0.42857143,\n",
       "         0.44871795,  1.        ],\n",
       "       [ 0.44      ,  0.53571429,  0.75      ,  0.875     ,  0.71428571,\n",
       "         0.59294872,  1.        ],\n",
       "       [ 0.38      ,  0.5       ,  0.25      ,  0.375     ,  0.28571429,\n",
       "         0.38461538,  0.        ],\n",
       "       [ 0.58      ,  0.5       ,  0.5       ,  0.75      ,  0.42857143,\n",
       "         0.38461538,  1.        ],\n",
       "       [ 0.56      ,  0.53571429,  0.5       ,  0.5       ,  0.57142857,\n",
       "         0.47115385,  1.        ],\n",
       "       [ 0.18      ,  0.07142857,  0.        ,  0.        , -0.14285714,\n",
       "         0.17307692,  0.        ],\n",
       "       [ 0.58      ,  0.39285714,  0.75      ,  0.875     ,  0.57142857,\n",
       "         0.59615385,  0.        ],\n",
       "       [ 0.68      ,  0.28571429,  0.5       ,  0.75      ,  1.        ,\n",
       "         0.58974359,  1.        ],\n",
       "       [ 0.8       ,  0.78571429,  0.75      ,  0.875     ,  0.42857143,\n",
       "         0.75961538,  1.        ],\n",
       "       [ 0.9       ,  0.89285714,  1.        ,  1.        ,  1.        ,\n",
       "         0.96794872,  1.        ],\n",
       "       [ 0.36      ,  0.42857143,  0.25      ,  0.375     ,  0.42857143,\n",
       "         0.40705128,  0.        ],\n",
       "       [ 0.6       ,  0.57142857,  0.5       ,  0.625     ,  0.71428571,\n",
       "         0.52564103,  1.        ],\n",
       "       [ 0.68      ,  0.53571429,  1.        ,  0.625     ,  0.71428571,\n",
       "         0.59615385,  1.        ],\n",
       "       [ 1.        ,  0.71428571,  0.75      ,  1.        ,  0.85714286,\n",
       "         0.91666667,  1.        ],\n",
       "       [ 0.56      ,  0.60714286,  0.5       ,  0.5       ,  0.42857143,\n",
       "         0.54487179,  0.        ],\n",
       "       [ 0.3       ,  0.35714286,  0.25      ,  0.25      ,  0.28571429,\n",
       "         0.44230769,  0.        ],\n",
       "       [ 0.5       ,  0.42857143,  0.5       ,  0.5       ,  0.28571429,\n",
       "         0.49038462,  0.        ],\n",
       "       [ 0.72      ,  0.78571429,  0.5       ,  0.5       ,  0.42857143,\n",
       "         0.74038462,  1.        ],\n",
       "       [ 0.4       ,  0.25      ,  0.25      ,  0.125     ,  0.14285714,\n",
       "         0.16025641,  0.        ],\n",
       "       [ 0.96      ,  0.89285714,  0.75      ,  0.625     ,  0.85714286,\n",
       "         0.8525641 ,  1.        ],\n",
       "       [ 0.28      ,  0.53571429,  0.5       ,  0.625     ,  0.42857143,\n",
       "         0.33974359,  0.        ],\n",
       "       [ 0.84      ,  0.57142857,  1.        ,  0.875     ,  0.71428571,\n",
       "         0.71153846,  1.        ],\n",
       "       [ 0.66      ,  0.67857143,  1.        ,  0.75      ,  1.        ,\n",
       "         0.98076923,  1.        ],\n",
       "       [ 0.6       ,  0.42857143,  0.5       ,  0.5       ,  0.28571429,\n",
       "         0.56730769,  1.        ],\n",
       "       [ 0.48      ,  0.60714286,  0.75      ,  0.625     ,  0.71428571,\n",
       "         0.63141026,  1.        ],\n",
       "       [ 0.74      ,  0.57142857,  1.        ,  1.        ,  0.57142857,\n",
       "         0.74679487,  1.        ],\n",
       "       [ 0.        ,  0.42857143,  0.75      ,  0.25      ,  0.28571429,\n",
       "         0.21153846,  0.        ],\n",
       "       [ 0.9       ,  0.92857143,  1.        ,  0.875     ,  0.57142857,\n",
       "         0.84615385,  1.        ],\n",
       "       [ 0.74      ,  0.5       ,  0.75      ,  0.75      ,  0.85714286,\n",
       "         0.625     ,  1.        ],\n",
       "       [ 0.64      ,  0.64285714,  1.        ,  0.875     ,  0.71428571,\n",
       "         0.69551282,  0.        ],\n",
       "       [ 0.36      ,  0.60714286,  0.25      ,  0.5       ,  0.71428571,\n",
       "         0.52884615,  0.        ],\n",
       "       [ 0.68      ,  0.75      ,  1.        ,  0.75      ,  1.        ,\n",
       "         0.78525641,  1.        ],\n",
       "       [ 0.82      ,  0.85714286,  1.        ,  0.75      ,  0.71428571,\n",
       "         0.78846154,  1.        ],\n",
       "       [ 0.14      ,  0.25      ,  0.75      ,  0.5       ,  0.57142857,\n",
       "         0.32371795,  0.        ],\n",
       "       [ 0.28      ,  0.42857143,  0.5       ,  0.375     ,  0.14285714,\n",
       "         0.42307692,  0.        ],\n",
       "       [ 0.38      ,  0.46428571,  0.75      ,  0.625     ,  0.14285714,\n",
       "         0.44230769,  0.        ],\n",
       "       [ 0.62      ,  0.35714286,  0.5       ,  0.625     ,  0.71428571,\n",
       "         0.70833333,  1.        ],\n",
       "       [ 0.52      ,  0.39285714,  0.5       ,  0.625     ,  0.14285714,\n",
       "         0.28205128,  0.        ],\n",
       "       [ 0.62      ,  0.60714286,  0.5       ,  0.5       ,  0.71428571,\n",
       "         0.44871795,  1.        ],\n",
       "       [ 0.64      ,  0.71428571,  0.75      ,  0.625     ,  0.28571429,\n",
       "         0.71153846,  1.        ],\n",
       "       [ 0.74      ,  0.67857143,  0.75      ,  0.75      ,  0.85714286,\n",
       "         0.70512821,  1.        ],\n",
       "       [ 0.64      ,  0.78571429,  1.        ,  0.875     ,  0.71428571,\n",
       "         0.68589744,  1.        ],\n",
       "       [ 0.16      ,  0.21428571,  0.25      ,  0.75      ,  0.42857143,\n",
       "         0.39423077,  0.        ],\n",
       "       [ 0.52      ,  0.64285714,  0.5       ,  0.625     ,  0.71428571,\n",
       "         0.56410256,  0.        ],\n",
       "       [ 0.3       ,  0.57142857,  1.        ,  0.5       ,  0.42857143,\n",
       "         0.53846154,  0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3da401e-09de-4239-87ee-880dc082f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dceb4517-9f3d-4257-af02-c117a13935ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "929defad-c308-4185-9e2b-83e86f3e0127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc2ee08d-a981-4940-80b3-f398959118cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m8\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09a556d6-8e06-45e4-bb7f-c390913d902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error',optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cd5a78d-bd33-4eff-993c-6d11651c588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4334 - val_loss: 0.3994\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3376 - val_loss: 0.3021\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2576 - val_loss: 0.2098\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1758 - val_loss: 0.1326\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1114 - val_loss: 0.0752\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0647 - val_loss: 0.0419\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0352 - val_loss: 0.0277\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0291 - val_loss: 0.0241\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0279 - val_loss: 0.0233\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0257 - val_loss: 0.0228\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0233 - val_loss: 0.0222\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0231 - val_loss: 0.0217\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0236 - val_loss: 0.0212\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0205 - val_loss: 0.0203\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0204 - val_loss: 0.0198\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0194\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0189\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0212 - val_loss: 0.0185\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0180\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - val_loss: 0.0176\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0167\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0158\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0161 - val_loss: 0.0154\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0169 - val_loss: 0.0147\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0147 - val_loss: 0.0141\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0164 - val_loss: 0.0134\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0143 - val_loss: 0.0128\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - val_loss: 0.0107\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0083\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0074\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0044\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8afadaf-dd99-4b3d-94f0-b3421d916b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cee96e12-ef82-4418-ba9b-59903265208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30a58a66-7f5a-4f2a-8a6c-b61c30d14b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7942095000650391"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5979705-a4ac-46cf-8d15-6036856117cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9522327-6644-4db7-b5bc-8ff53f0bc4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2171092ed20>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a1a03-8aab-4075-a092-2dbabcd7ccf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
